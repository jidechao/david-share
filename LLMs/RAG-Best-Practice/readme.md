# 使用AI搜索的RAG最佳实践

尽管像GPT-4和GPT-3.5这样的模型非常强大，但它们的知识可能不是最新的。以前，我们经常在LLM的使用中引入工程技术，将提示工程、RAG和微调视为并行的方法。事实上，这三种技术可以结合起来使用。

## RAG的四个阶段

我读到的论文中的思路非常出色——它将RAG分为四个阶段。

![图片](https://mmbiz.qpic.cn/mmbiz_png/akGXyic486nUtDdUuMGNicTShl7ib3NKD1NlRyzggptGGCpJs4YOreYt9tqTxjfGsvKlIkSVMHadX0tVKJT2PaP4A/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 第一级：显式事实查询

### 特点

**简单性**：直接从提供的数据中检索显式的事实信息，无需复杂的推理或多步处理。

**要求**：高效且准确地检索相关内容并生成精确的答案。

### 技术与工程建议

#### a. 基本RAG方法

- 数据预处理和分块

  ：将长文本或文档划分为适当的分块以便索引和检索。常见的分块策略包括：

  - **固定长度分块**：按固定长度分割文本，可能会打断句子或段落。
  - **基于段落或语义的分块**：根据自然段落或语义边界进行分块，以保持内容的完整性。

- 索引构建：

  - **稀疏索引**：使用传统的信息检索方法，如TF-IDF或BM25，基于关键词匹配。
  - **密集索引**：使用预训练的语言模型（如BERT）生成文本向量嵌入，用于向量检索。

- 检索技术：

  - 利用向量相似度计算或关键词匹配从索引中检索最相关的文本片段。

- 答案生成：

  - 将检索到的文本片段作为上下文输入LLM，生成最终答案。

#### b. 改进检索和生成阶段

- **多模态数据处理**：如果数据包含表格、图像或其他非文本信息，将其转换为文本形式或使用多模态模型进行处理。
- 检索优化：
  - **递归检索**：当单次检索不足以找到答案时，进行多轮检索，逐步缩小范围。
  - **检索结果重排序**：使用模型对检索结果进行评分或重排序，优先选择最相关的内容。
- 生成优化：
  - **过滤无关信息**：在生成阶段之前，过滤掉与问题无关的检索内容，避免干扰模型的输出。
  - **控制答案格式**：通过精心设计的提示，确保模型生成格式正确且内容准确的答案。

### 工程实践示例

**示例**：构建一个问答系统，回答关于公司产品的常见问题。

- 数据准备：
  - 收集所有相关的产品文档、常见问题解答、用户手册等。
  - 清理、分块并索引文档。
- 系统实现：
  - 用户提问后，使用密集向量检索从索引中找到最相关的文本片段。
  - 将检索到的片段作为上下文输入LLM，生成答案。
- 优化策略：
  - 定期更新文档和索引，确保信息是最新的。
  - 监控用户反馈，改进检索策略和提示设计，提高答案质量。

## 第二级：隐式事实查询

### 特点

- **复杂性增加**：需要基于检索到的数据进行一定程度的推理或多步推导。
- **要求**：模型需要将问题分解为多个步骤，分别检索和处理，然后综合出最终答案。

### 技术与工程建议

#### a. 多跳检索与推理

- 迭代RAG：
  - **IRCoT（迭代检索思维链）**：使用思维链推理引导模型在每一步检索相关信息，逐步接近答案。
  - **RAT（带思考的检索与回答）**：在回答过程中引入检索步骤，允许模型在需要时检索新信息。
- 问题分解：
  - 将复杂问题分解为更简单的子问题，分别检索和回答，然后综合结果。

#### b. 图或树结构的检索与推理

- 构建知识图谱：
  - 从数据中提取实体和关系，构建知识图谱，帮助模型理解复杂的依赖关系。
- 图搜索算法：
  - 使用深度优先搜索（DFS）或广度优先搜索（BFS）等算法在知识图谱中查找与问题相关的路径或子图。

#### c. 使用SQL或其他结构化查询

- 文本到SQL转换：
  - 将自然语言问题转换为SQL查询，从结构化数据库中检索答案。
- 工具支持：
  - 使用现有的文本到SQL转换工具（如Chat2DB），促进自然语言到数据库查询的转换。

### 工程实践示例

**场景**：用户提问：“过去五年中，公司X的股价在哪些季度超过了公司Y？”

**问题分解**：

1. 获取过去五年公司X和公司Y的季度股价数据。

2. 比较每个季度的股价。

3. 找出公司X股价超过公司Y的季度。

   **实现步骤**：

- **步骤1**：使用文本到SQL工具将自然语言查询转换为SQL查询，并从数据库中检索相关数据。

- **步骤2**：使用编程语言（如Python）处理并比较数据。

- **步骤3**：将结果整理为用户可读的格式。

  **答案生成**：将整理后的结果作为上下文输入LLM，生成自然语言回答。

## 第三级：可解释的推理查询

### 特点

- **应用特定领域的规则和指南**：模型需要理解并遵循通常不在预训练数据中的规则。
- **要求**：将外部规则、指南或流程集成到模型中，使其在回答时能够遵循指定的逻辑和步骤。

### 技术与工程建议

#### a. 提示工程与提示优化

- 设计有效的提示：
  - 在提示中明确提供规则或指南，引导模型在回答时遵循指定的步骤。
- 自动提示优化：
  - 使用优化算法（如强化学习）自动搜索和优化提示，提高模型在特定任务上的表现。
  - **OPRO（通过提示重写优化）**：模型自行生成和评估提示，迭代优化以找到最佳提示组合。

#### b. 思维链（CoT）提示

- 引导多步推理：
  - 在提示中要求模型展示其推理过程，确保其遵循指定的逻辑。
- 手动或自动CoT提示设计：
  - 根据任务需求设计适当的CoT提示，或使用算法自动生成。

#### c. 遵循外部流程或决策树

- 编码规则和流程：
  - 将决策流程转换为状态机、决策树或伪代码，供模型执行。
- 模型调整：
  - 使模型能够解析并执行这些编码的规则。

### 工程实践示例

**示例**：处理退货请求的客户服务聊天机器人。

**场景**：客户请求退货。聊天机器人需要根据公司的退货政策引导客户完成适当的流程。

**技术实现**：

- 规则集成：

  - 将公司的退货政策和流程整理为清晰的步骤或决策树。

- 提示设计：

  - 在提示中包含退货政策的关键点，要求模型逐步引导客户。

- 模型执行：

  - LLM根据提示与客户互动，按照退货流程提供清晰的指导。

    **优化策略**：

- 提示优化：

  - 根据客户反馈调整提示，帮助模型更准确地理解和执行退货流程。

- 多轮对话：

  - 支持与客户的多轮对话，处理各种潜在问题和例外情况。

## 第四级：隐藏推理查询

### 特点

- **最高复杂性**：涉及特定领域的隐含推理方法；模型需要从数据中发现并应用这些隐藏的逻辑。
- **要求**：模型必须能够从大量数据中挖掘模式并应用推理方法，类似于领域专家的思维过程。

### 技术与工程建议

#### a. 离线学习与经验积累

- 从数据中学习模式和经验：
  - 训练模型从历史数据和案例中归纳出潜在的规则和逻辑。
- 自监督学习：
  - 使用模型生成的推理过程（如思维链）作为辅助信息，优化模型的推理能力。

#### b. 上下文学习（ICL）

- 提供示例和案例：
  - 在提示中包含相关示例，供模型在推理时参考类似案例。
- 检索相关案例：
  - 使用检索模块从数据库中查找与当前问题相似的案例，并提供给模型。

#### c. 模型微调

- 领域特定微调：
  - 使用大量领域数据对模型进行微调，使其内化领域知识。
- 强化学习：
  - 使用奖励机制鼓励模型生成期望的推理过程和答案。

### 工程实践示例

**示例**：处理复杂案件的法律助手AI。

**场景**：用户咨询一个复杂的法律问题。AI需要提供建议，并引用相关法律条款和判例。

**技术实现**：

- 数据准备：

  - 收集大量法律文档、案例分析、专家意见等。

- 模型微调：

  - 使用法律领域数据对LLM进行微调，使其具备法律推理能力。

- 案例检索：

  - 使用RAG从数据库中检索相关判例和法律条款。

- 答案生成：

  - 将检索到的案例和条款作为上下文输入微调后的LLM，生成专业的法律建议。

    **优化策略**：

- 持续学习：

  - 定期更新模型，添加新的法律案例和法规变化。

- 专家审查：

  - 引入法律专家审查模型的输出，确保其准确性和合法性。

## 综合考量：结合微调LLM与RAG

尽管微调LLM可以增强模型的推理能力和领域适应性，但它不能完全替代RAG的作用。RAG在处理动态、海量和实时更新的知识方面具有独特的优势。结合微调和RAG，可以发挥各自的优势，使模型在具备强大推理能力的同时，能够访问最新、最全面的外部知识。

### 结合的优势

- 增强推理能力：
  - 通过微调，模型学习特定领域的推理方法和逻辑。
- 实时知识访问：
  - RAG使模型在生成答案时能够实时检索最新的外部数据。
- 灵活性与可扩展性：
  - RAG系统可以轻松更新数据源，而无需重新训练模型。

### 实际应用建议

- 结合微调与RAG处理复杂任务：
  - 使用微调增强模型的推理和逻辑能力，同时使用RAG获取特定知识和信息。
- 评估成本效益：
  - 考虑微调的成本和收益；专注于微调核心推理能力，让RAG处理知识获取。
- 持续更新与维护：
  - 为RAG系统建立数据更新机制，确保模型访问的外部数据是最新且准确的。

## RAG详细技术解释

检索增强生成（RAG）是一种将大型语言模型（LLM）与信息检索相结合的技术。它通过在生成过程中检索和利用外部知识库中的相关信息，增强模型的能力。这为模型提供了最新的、特定领域的知识，使其能够生成更准确和上下文相关的回答。

![图片](https://mmbiz.qpic.cn/mmbiz_png/akGXyic486nV8iccIwibpABEdicffYMy77GDXFYUR4MEmsibdwPE4XzSudU52gQL0cBAJeiaId5EltiaHguq952P0e7xg/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## RAG的目的

**为什么需要RAG？**

- **减少幻觉**：当LLM缺乏足够的上下文时，可能会产生不准确或虚假的信息，称为“幻觉”。RAG通过提供实时的外部信息，减少幻觉的发生。

- **更新知识**：LLM的预训练数据可能滞后于当前信息。RAG使模型能够访问最新的数据源，保持信息的时效性。

- **提高准确性**：通过检索相关背景信息，模型的回答更加准确和专业。

### RAG的工作原理

RAG的核心思想是从文档库中检索相关信息，并将其与用户的查询一起输入LLM，引导模型生成更准确的答案。一般流程如下：

- **用户查询**：用户向系统提出问题或请求。
- **检索阶段**：系统使用查询从文档库或知识库中检索相关文档片段（块）。
- **生成阶段**：将检索到的文档片段与原始查询一起输入LLM，生成最终答案。

### 构建RAG系统的关键步骤

### 明确目标

在开始构建RAG系统之前，首先需要明确目标：

- **升级搜索界面**：是否希望在现有搜索界面中添加语义搜索功能？

- **增强领域知识**：是否希望利用特定领域的知识来增强搜索或聊天功能？

- **添加聊天机器人**：是否希望添加一个聊天机器人与客户互动？

- **暴露内部API**：是否计划通过用户对话暴露内部API？

  明确的目标将指导整个实施过程，并帮助您选择最合适的技术和策略。

### 数据准备

数据是RAG系统的基础，其质量直接影响系统性能。数据准备包括以下步骤：

**(1) 评估数据格式**

- **结构化数据**：如CSV、JSON等，需要转换为文本格式以便索引和检索。

- **表格数据**：可能需要转换或丰富，以支持更复杂的搜索或交互。

- **文本数据**：如文档、文章、聊天记录等，可能需要整理或过滤。

- **图像数据**：包括流程图、文档、照片等。

  **(2) 数据丰富**

- **添加上下文信息**：补充数据，如知识库或行业信息。

- **数据标注**：标注关键实体、概念和关系，增强模型的理解能力。

  **(3) 选择合适的平台**

- **向量数据库**：如AI Search、Qdrant等，用于存储和检索嵌入向量。

- **关系数据库**：数据库模式需要包含在LLM的提示中，以便将用户请求转换为SQL查询。

- **文本搜索引擎**：如AI Search、Elasticsearch、Couchbase，可以与向量搜索结合，发挥文本和语义搜索的优势。

- **图数据库**：构建知识图谱，利用节点之间的连接和语义关系。

## 文档分块

在RAG系统中，文档分块是一个关键步骤，直接影响检索信息的质量和相关性。以下是分块的最佳实践：

- 模型限制：LLM有最大上下文长度限制。
- 提高检索效率：将大文档分割为较小的块有助于提高检索的准确性和速度。

**分块方法**

- **固定大小分块**：定义固定大小（如200字）的块，并允许一定程度的重叠（如10-15%）。
- **基于内容的可变大小分块**：根据内容特征（如句子、段落、Markdown结构）进行分块。
- **自定义或迭代分块策略**：结合固定大小和可变大小方法，并根据具体需求进行调整。

**内容重叠的重要性**

- **保留上下文**：在分块时允许块之间有一定的重叠，有助于保留上下文信息。
- **建议**：从大约10%的重叠开始，根据具体数据类型和用例进行调整。

## 选择合适的嵌入模型

嵌入模型用于将文本转换为向量形式，以便进行相似度计算。选择嵌入模型时，考虑：

- **模型输入限制**：确保输入文本长度在模型允许的范围内。

- **模型性能和效果**：根据具体应用场景选择性能良好且效果合适的模型。

  ![图片](https://github.com/xinyuwei-david/david-share/blob/master/LLMs/RAG-Best-Practice/images/1.png)

**新嵌入模型**：OpenAI推出了两个新的嵌入模型：`text-embedding-3-small`和`text-embedding-3-large`。

**模型大小与性能**：`text-embedding-3-large`是一个更大、更强大的嵌入模型，能够创建最多3072维的嵌入。

**性能改进**：

- **MIRACL基准**：`text-embedding-3-large`在MIRACL基准上得分为**54.9**，相比`text-embedding-ada-002`的**31.4**有显著提升。

- **MTEB基准**：`text-embedding-3-large`在MTEB基准上得分为**64.6**，超过了`text-embedding-ada-002`的**61.0**。

  **改进分析**：

- **更高维度**：`text-embedding-3-large`能够创建最多3072维的嵌入，使其能够更好地捕捉和表示内容中的概念和关系。

- **改进的训练技术**：新模型采用了更先进的训练技术和优化方法，在多语言检索和英语任务上表现更好。

- **灵活性**：`text-embedding-3-large`允许开发者通过调整嵌入的维度来平衡性能和成本。例如，将3072维的嵌入减少到256维，仍然可以在MTEB基准上超过未压缩的`text-embedding-ada-002`。

**注意**：

要从`text-embedding-ada-002`迁移到`text-embedding-3-large`，您需要手动生成新的嵌入，因为嵌入模型之间的升级不是自动的。第一步是在您的Azure环境中部署新模型（text-embedding-3-large）。之后，重新生成所有数据的嵌入，因为旧模型的嵌入与新模型不兼容。

## AI搜索服务的容量与性能优化

### 服务层级与容量

**参考**：*https://learn.microsoft.com/en-us/azure/search/search-limits-quotas-capacity*

- **升级服务层级**：从标准S1升级到S2可以提供更高的性能和存储容量。

- **增加分区和副本**：根据查询负载和索引大小进行调整。

- **避免复杂查询**：减少使用高开销的查询，如正则表达式查询。

- **查询优化**：仅检索所需字段，限制返回的数据量，使用搜索功能而非复杂过滤器。

  ![图片](https://github.com/xinyuwei-david/david-share/blob/master/LLMs/RAG-Best-Practice/images/2.png)

  ### 提高Azure AI搜索性能的技巧

  - **索引大小与架构**：定期优化索引；删除不必要的字段和文档。
  - **查询设计**：优化查询语句，减少不必要的扫描和计算。
  - **服务容量**：根据查询负载和索引大小适当调整副本和分区。
  - **避免复杂查询**：减少使用高开销的查询，如正则表达式查询。

  ### 分块大文档

  - **使用内置的文本分割技能**：根据需要选择`pages`或`sentences`模式。
  - **调整参数**：根据文档特征设置适当的`maximumPageLength`、`pageOverlapLength`等。
  - **使用LangChain等工具**：进行更灵活的分块和嵌入操作。

  ### L1+L2搜索 + 查询重写与新语义重排序器

  - **L1混合搜索+L2重排序器**：增强搜索结果

    ![图片](https://github.com/xinyuwei-david/david-share/blob/master/LLMs/RAG-Best-Practice/images/9.png)

  - **查询重写**：通过重写用户查询来提高召回率和准确性。
  
  - **语义重排序器**：使用交叉编码器对候选结果进行重排序，提高结果的相关性。
  
  ![图片](https://github.com/xinyuwei-david/david-share/blob/master/LLMs/RAG-Best-Practice/images/8.png)

***请点击下方图片查看我在Yutube上的查询重写演示视频***：
[![查询重写演示1](https://raw.githubusercontent.com/xinyuwei-david/david-share/refs/heads/master/IMAGES/6.webp)](https://www.youtube.com/watch?v=uMDOpPzFfsc)

在上面的演示中，我将重写查询的数量从1增加到3，显著提高了搜索结果的准确性。完整的答案应由四个结果组成。当重写查询向量的数量为1时，只能检索到三个结果。

示例代码：

```
import requests  
import json  
  
url = 'https://ai-search-eastus-xinyuwei.search.windows.net/indexes/wukong-doc1/docs/search'  
params = {  
    'api-version': '2024-11-01-preview'  
}  
  
headers = {  
    'Content-Type': 'application/json',  
    'api-key': '**'  
}  
  
payload = {  
    "search": "What the hell is Black Myth Goku?",  
    "semanticConfiguration": "wukong-doc1-semantic-configuration",  
    "queryType": "semantic",  
    "queryRewrites": "generative|count-5",  
    "queryLanguage": "en-US",  
    "debug": "queryRewrites",  
    "top": 1  
}  
  
response = requests.post(url, params=params, headers=headers, json=payload)  
  
print('状态码:', response.status_code)  
print('响应体:', json.dumps(response.json(), indent=2, ensure_ascii=False))  
```

输出：

```
状态码: 200
响应体: {
  "@odata.context": "https://ai-search-eastus-xinyuwei.search.windows.net/indexes('wukong-doc1')/$metadata#docs(*)",
  "@search.debug": {
    "semantic": null,
    "queryRewrites": {
      "text": {
        "inputQuery": "What the hell is Black Myth Goku?",
        "rewrites": [
          "Black Myth Goku游戏详情",
          "什么是Black Myth Goku？",
          "Black Myth Goku的解释",
          "理解Black Myth Goku",
          "Black Myth Goku指南"
        ]
      },
      "vectors": []
    }
  },
  "value": [
    {
      "@search.score": 10.368155,
      "@search.rerankerScore": 2.3498611450195312,
```

## 提示工程

1. **使用丰富的示例**：提供多个示例以引导模型学习并改进其回答。
2. **提供清晰的指令**：确保指令明确且无歧义，以避免误解。
3. **限制输入和输出格式**：定义可接受的输入和输出格式，防止恶意内容并保护模型安全。

**注意**：提示工程不适用于Azure OpenAI o1

参考：*https://mp.weixin.qq.com/s/tLcAfPU6hUkFsNMjDFeklw?token=1531586958&lang=zh_CN*

```

您的任务是审查客户问题并将其分类为以下4种问题类型之一。

审查步骤如下，请逐步执行：

1. 从客户问题中提取三个关键词并将其翻译成英文。请将这三个关键词用逗号连接，使其成为一个完整的JSON值。

2. 用15个单词总结客户的问题，并用英文表达。

3. 根据审查文本和总结对客户的问题进行分类。分类列表：
    • 技术问题：客户遇到服务器端问题、客户端错误或产品限制。示例：“我无法登录我的账户。它一直显示服务器错误。”
    • 产品咨询：客户希望了解更多产品详情或询问如何使用产品。示例：“你能提供更多关于产品的信息以及如何使用它吗？”
    • 申请状态：客户要求检查其Azure OpenAI、GPT-4或DALLE申请的状态。示例：“我的Azure OpenAI申请状态如何？”
    • 未知：如果您只有低置信度进行分类。示例：“我不确定这是否是正确的地方，但我有一个关于账单的问题。”

以JSON格式提供，包含以下键：案例ID；关键词；总结；类别。每个审查只生成一个JSON结构。

请以表格形式显示输出结果，表格分为四列：案例ID、关键词、总结、类别。
```

![图片](https://mmbiz.qpic.cn/mmbiz_png/akGXyic486nWf6Iogb0ScBpSFibiavMUk2TohHj9WylLC68Q6yDGOS8hG6PHWqiavicIVNbFbVCWYeKEBMDQ1eg3hRA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
